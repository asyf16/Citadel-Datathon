{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0euruw5aa8f8",
   "source": "# Statistical Analysis: Market Reactions to AI Adoption Disclosures\n\n**Research question:** Do AI adoption announcements trigger abnormal trading intensity and volatility, does AI-related CapEx amplify those effects, and have the effects attenuated over time (2015 → 2025) as AI became mainstream?\n\n**Core hypothesis:** Early AI announcements triggered outsized market reactions (volume spikes, volatility jumps), but as AI became commonplace, the same type of disclosure now generates a muted response.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ejamwo8bfuf",
   "source": "import sys, os, warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\nsns.set_theme(style=\"whitegrid\")\nplt.rcParams.update({\"figure.dpi\": 120, \"savefig.dpi\": 150, \"font.size\": 11})\n\nfrom src.statistical_analysis import (\n    load_analysis_data, assign_period_bin, get_event_window,\n    compute_event_abnormal_volume_stats, compute_event_volatility_stats,\n    match_capex_to_events, classify_capex_high_low,\n    test_abnormal_volume_significance, test_paired_volatility_change,\n    test_period_differences, test_capex_group_difference,\n    run_ols_regression,\n    plot_abnormal_volume_by_period, plot_volatility_change_by_period,\n    plot_capex_interaction, plot_time_trend_line, format_test_results_table,\n    COLOR_VOLUME, COLOR_VOLATILITY, COLOR_CAPEX, FIGURE_DIR,\n)\nfrom src.event_study import compute_returns\n\nprint(\"Setup complete.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "p0kwzx4zauo",
   "source": "# --- Data Loading ---\ndata = load_analysis_data()\nevents = data[\"events\"].copy()\nprices = data[\"prices\"].copy()\nspy_prices = data[\"spy_prices\"].copy()\nedgar = data[\"edgar\"].copy()\nticker_dim = data[\"ticker_dim\"].copy()\ngenai_dim = data[\"genai_dim\"].copy()\n\n# Add period bins and sector info\nevents[\"period_bin\"] = events[\"announcement_date\"].apply(assign_period_bin)\nevents = events.merge(ticker_dim[[\"ticker\", \"sector\"]], on=\"ticker\", how=\"left\")\n# Fill missing sector from industry column if available\nif \"industry\" in events.columns:\n    events[\"sector\"] = events[\"sector\"].fillna(events[\"industry\"])\n\nprint(f\"Events: {len(events)} | Stocks: {prices['ticker'].nunique()} tickers\")\nprint(f\"Price rows: {len(prices):,} | EDGAR rows: {len(edgar):,}\")\nprint(f\"Data source: {'Mock' if not data.get('_using_real', {}).get('events') else 'Real CSV'}\")\nprint(f\"\\nEvents by period:\\n{events['period_bin'].value_counts().sort_index()}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "z5w2vdywac8",
   "source": "## 1. Exploratory Data Analysis",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "phghc6lbvl",
   "source": "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\n# Events by year\nevents[\"year\"] = events[\"announcement_date\"].dt.year\nevents.groupby(\"year\").size().plot.bar(ax=axes[0], color=COLOR_VOLUME, edgecolor=\"white\")\naxes[0].set_title(\"AI Disclosure Events by Year\")\naxes[0].set_xlabel(\"Year\")\naxes[0].set_ylabel(\"Count\")\n\n# Events by sector\nsector_counts = events[\"sector\"].value_counts()\nsector_counts.plot.barh(ax=axes[1], color=COLOR_VOLUME, edgecolor=\"white\")\naxes[1].set_title(\"Events by Sector\")\naxes[1].set_xlabel(\"Count\")\n\n# Events by agent type\nevents[\"agent_type\"].value_counts().plot.bar(ax=axes[2], color=COLOR_VOLUME, edgecolor=\"white\")\naxes[2].set_title(\"Events by Agent Type\")\naxes[2].set_xlabel(\"\")\naxes[2].set_ylabel(\"Count\")\n\nfig.suptitle(\"Event Distribution Overview\", fontsize=14, y=1.02)\nfig.tight_layout()\nfig.savefig(FIGURE_DIR / \"stat_eda_overview.png\", dpi=150, bbox_inches=\"tight\")\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "pm1dcipbjs",
   "source": "## 2. Trading Intensity (Abnormal Volume)\n\n**Abnormal Volume** = mean event-window volume / mean pre-event volume. A ratio > 1 indicates abnormally high trading activity around the announcement.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "znkju1bovqq",
   "source": "# Compute abnormal volume for all events\nabvol_df = compute_event_abnormal_volume_stats(prices, events)\nabvol_df[\"period_bin\"] = abvol_df[\"announcement_date\"].apply(assign_period_bin)\n\nprint(\"Abnormal volume summary (window [0, +5]):\")\nprint(abvol_df[\"abvol_0_5\"].describe().round(3))\nprint(f\"\\nNon-null observations: {abvol_df['abvol_0_5'].notna().sum()}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ogjkzwgw69r",
   "source": "# Statistical tests: is abnormal volume significantly > 1?\nwindows = [\"abvol_-1_1\", \"abvol_0_5\", \"abvol_0_10\", \"abvol_0_20\"]\nabvol_tests = {}\nfor w in windows:\n    result = test_abnormal_volume_significance(abvol_df[w])\n    abvol_tests[w] = result\n    sig = \"***\" if result[\"t_pval\"] < 0.001 else (\"**\" if result[\"t_pval\"] < 0.01 else (\"*\" if result[\"t_pval\"] < 0.05 else \"ns\"))\n    print(f\"{w}: mean={result['mean']:.3f}, t={result['t_stat']:.3f}, \"\n          f\"p(t)={result['t_pval']:.4f} {sig}, p(W)={result['w_pval']:.4f}, n={result['n']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "lrpraobcwy",
   "source": "# 4-panel histogram of AbVol distributions by window\nfig, axes = plt.subplots(2, 2, figsize=(12, 9))\nfor ax, w in zip(axes.flat, windows):\n    vals = abvol_df[w].dropna()\n    ax.hist(vals, bins=30, color=COLOR_VOLUME, edgecolor=\"white\", alpha=0.8)\n    ax.axvline(x=1.0, color=\"red\", linestyle=\"--\", label=\"No abnormal volume\")\n    ax.axvline(x=vals.mean(), color=\"navy\", linestyle=\"-\", linewidth=2, label=f\"Mean={vals.mean():.3f}\")\n    ax.set_title(f\"Abnormal Volume: {w}\")\n    ax.set_xlabel(\"Volume Ratio\")\n    ax.set_ylabel(\"Frequency\")\n    ax.legend(fontsize=9)\n\nfig.suptitle(\"Distribution of Abnormal Volume Across Event Windows\", fontsize=13)\nfig.tight_layout()\nfig.savefig(FIGURE_DIR / \"stat_abvol_distributions.png\", dpi=150, bbox_inches=\"tight\")\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "aspscka9j3g",
   "source": "## 3. Volatility Analysis\n\nCompare realized volatility (std of daily returns) in pre-event vs. post-event windows. Also compute maximum drawdown in abnormal returns post-event.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "cwqz9vrun98",
   "source": "# Compute volatility stats\nvol_df = compute_event_volatility_stats(prices, spy_prices, events)\nvol_df[\"period_bin\"] = vol_df[\"announcement_date\"].apply(assign_period_bin)\n\nprint(\"Volatility change summary (post - pre):\")\nprint(vol_df[\"vol_change\"].describe().round(6))\nprint(f\"\\nMax drawdown summary:\")\nprint(vol_df[\"max_drawdown\"].describe().round(6))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "wraty9g2fef",
   "source": "# Paired t-test: pre_vol vs post_vol\nvol_test = test_paired_volatility_change(vol_df[\"pre_vol\"], vol_df[\"post_vol\"])\nprint(\"Paired volatility test (H0: pre_vol = post_vol):\")\nfor k, v in vol_test.items():\n    print(f\"  {k}: {v:.4f}\" if isinstance(v, float) else f\"  {k}: {v}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6qr2d1hirta",
   "source": "# 3-panel: scatter (pre vs post), hist (vol change), hist (drawdown)\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\n# Pre vs Post volatility scatter\nvalid = vol_df.dropna(subset=[\"pre_vol\", \"post_vol\"])\naxes[0].scatter(valid[\"pre_vol\"], valid[\"post_vol\"], alpha=0.5, s=20, color=COLOR_VOLATILITY)\nlims = [0, max(valid[\"pre_vol\"].max(), valid[\"post_vol\"].max()) * 1.1]\naxes[0].plot(lims, lims, \"k--\", alpha=0.5, label=\"45-degree line\")\naxes[0].set_xlabel(\"Pre-event Volatility\")\naxes[0].set_ylabel(\"Post-event Volatility\")\naxes[0].set_title(\"Pre vs. Post-Event Volatility\")\naxes[0].legend()\n\n# Vol change histogram\naxes[1].hist(vol_df[\"vol_change\"].dropna(), bins=30, color=COLOR_VOLATILITY, edgecolor=\"white\", alpha=0.8)\naxes[1].axvline(x=0, color=\"red\", linestyle=\"--\")\naxes[1].set_xlabel(\"Volatility Change\")\naxes[1].set_ylabel(\"Frequency\")\naxes[1].set_title(\"Distribution of Volatility Change\")\n\n# Max drawdown histogram\naxes[2].hist(vol_df[\"max_drawdown\"].dropna(), bins=30, color=COLOR_VOLATILITY, edgecolor=\"white\", alpha=0.8)\naxes[2].set_xlabel(\"Max Drawdown (|CAR|)\")\naxes[2].set_ylabel(\"Frequency\")\naxes[2].set_title(\"Distribution of Max Drawdown\")\n\nfig.tight_layout()\nfig.savefig(FIGURE_DIR / \"stat_volatility_panels.png\", dpi=150, bbox_inches=\"tight\")\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "v8memuoisn",
   "source": "## 4. Time Trend Analysis\n\nHas the market reaction to AI disclosures diminished over time? Compare abnormal volume and volatility change across period bins (2015-2017 → 2024-2025).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "22gyh3yk6ky",
   "source": "# Abnormal volume by period — box plot + trend line\nfig = plot_abnormal_volume_by_period(abvol_df, window_col=\"abvol_0_5\")\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2g0hb73l2vo",
   "source": "# Trend line with 95% CI\nfig = plot_time_trend_line(abvol_df, \"abvol_0_5\", title=\"Abnormal Volume [0,+5] Trend Over Time\")\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "n6g9olsid9k",
   "source": "# ANOVA / Kruskal-Wallis + pairwise tests for abnormal volume\nabvol_period_test = test_period_differences(abvol_df, \"abvol_0_5\", \"period_bin\")\n\nprint(\"=== Abnormal Volume Period Differences ===\")\nprint(f\"ANOVA:   F={abvol_period_test['f_stat']:.3f},  p={abvol_period_test['f_pval']:.4f}\")\nprint(f\"Kruskal: H={abvol_period_test['kw_stat']:.3f}, p={abvol_period_test['kw_pval']:.4f}\")\nprint(f\"\\nGroup sizes: {abvol_period_test['group_ns']}\")\nprint(f\"Group means: { {k: round(v,3) for k,v in abvol_period_test['group_means'].items()} }\")\nprint(\"\\nPairwise Mann-Whitney (Bonferroni-corrected):\")\nfor pair, res in abvol_period_test[\"pairwise\"].items():\n    sig = \"***\" if res[\"p_bonferroni\"] < 0.001 else (\"**\" if res[\"p_bonferroni\"] < 0.01 else (\"*\" if res[\"p_bonferroni\"] < 0.05 else \"ns\"))\n    print(f\"  {pair}: U={res['u_stat']:.0f}, p_adj={res['p_bonferroni']:.4f} {sig}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "y4d92553pc",
   "source": "# Volatility change by period\nfig = plot_volatility_change_by_period(vol_df)\nplt.show()\n\n# Trend line for vol change\nfig = plot_time_trend_line(vol_df, \"vol_change\", title=\"Volatility Change Trend Over Time\")\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fuwv14u7jym",
   "source": "# Period tests for volatility change\nvol_period_test = test_period_differences(vol_df, \"vol_change\", \"period_bin\")\n\nprint(\"=== Volatility Change Period Differences ===\")\nprint(f\"ANOVA:   F={vol_period_test['f_stat']:.3f},  p={vol_period_test['f_pval']:.4f}\")\nprint(f\"Kruskal: H={vol_period_test['kw_stat']:.3f}, p={vol_period_test['kw_pval']:.4f}\")\nprint(f\"\\nGroup sizes: {vol_period_test['group_ns']}\")\nprint(f\"Group means: { {k: f'{v:.6f}' for k,v in vol_period_test['group_means'].items()} }\")\nprint(\"\\nPairwise Mann-Whitney (Bonferroni-corrected):\")\nfor pair, res in vol_period_test[\"pairwise\"].items():\n    sig = \"***\" if res[\"p_bonferroni\"] < 0.001 else (\"**\" if res[\"p_bonferroni\"] < 0.01 else (\"*\" if res[\"p_bonferroni\"] < 0.05 else \"ns\"))\n    print(f\"  {pair}: U={res['u_stat']:.0f}, p_adj={res['p_bonferroni']:.4f} {sig}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "902pgfz8x46",
   "source": "## 5. CapEx Interaction\n\nDo firms with higher AI-related capital expenditure see stronger or weaker market reactions to AI disclosures? We match the most recent EDGAR filing before each announcement (no look-ahead bias) and split into High/Low CapEx groups via median split.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "a6wb2brangm",
   "source": "# Match EDGAR CapEx data to events\ncapex_df = match_capex_to_events(events, edgar)\ncapex_df[\"period_bin\"] = capex_df[\"announcement_date\"].apply(assign_period_bin)\n\nmatch_rate = capex_df[\"capex_intensity\"].notna().mean()\nprint(f\"EDGAR match rate: {match_rate:.1%} ({capex_df['capex_intensity'].notna().sum()} / {len(capex_df)})\")\nprint(f\"\\nCapEx intensity summary:\")\nprint(capex_df[\"capex_intensity\"].describe().round(2))\n\n# Add abnormal volume and vol change for regression\ncapex_df = capex_df.merge(\n    abvol_df[[\"ticker\", \"announcement_date\", \"abvol_0_5\"]],\n    on=[\"ticker\", \"announcement_date\"], how=\"left\"\n)\ncapex_df = capex_df.merge(\n    vol_df[[\"ticker\", \"announcement_date\", \"vol_change\"]],\n    on=[\"ticker\", \"announcement_date\"], how=\"left\"\n)\n\n# Median split\ncapex_df = classify_capex_high_low(capex_df)\nprint(f\"\\nHigh CapEx: {capex_df['high_capex'].sum()} | Low CapEx: {(1-capex_df['high_capex']).sum()}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fcn6sfvsdum",
   "source": "# High vs Low CapEx group comparison\nhigh_vals = capex_df.loc[capex_df[\"high_capex\"] == 1, \"abvol_0_5\"].dropna()\nlow_vals = capex_df.loc[capex_df[\"high_capex\"] == 0, \"abvol_0_5\"].dropna()\n\ncapex_test = test_capex_group_difference(high_vals, low_vals)\nprint(\"=== CapEx Group Difference (AbVol [0,+5]) ===\")\nfor k, v in capex_test.items():\n    print(f\"  {k}: {v:.4f}\" if isinstance(v, float) else f\"  {k}: {v}\")\n\n# Same for vol_change\nhigh_vol = capex_df.loc[capex_df[\"high_capex\"] == 1, \"vol_change\"].dropna()\nlow_vol = capex_df.loc[capex_df[\"high_capex\"] == 0, \"vol_change\"].dropna()\ncapex_vol_test = test_capex_group_difference(high_vol, low_vol)\nprint(\"\\n=== CapEx Group Difference (Vol Change) ===\")\nfor k, v in capex_vol_test.items():\n    print(f\"  {k}: {v:.6f}\" if isinstance(v, float) else f\"  {k}: {v}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fl8wkeyxf54",
   "source": "# Grouped bar: CapEx interaction with period\nfig = plot_capex_interaction(capex_df, reaction_col=\"abvol_0_5\")\nplt.show()\n\n# Scatter: CapEx intensity vs market reaction\nfig, axes = plt.subplots(1, 2, figsize=(13, 5))\n\nvalid = capex_df.dropna(subset=[\"capex_intensity\", \"abvol_0_5\"])\naxes[0].scatter(valid[\"capex_intensity\"], valid[\"abvol_0_5\"],\n                alpha=0.5, s=20, color=COLOR_CAPEX)\naxes[0].set_xlabel(\"CapEx Intensity\")\naxes[0].set_ylabel(\"Abnormal Volume [0,+5]\")\naxes[0].set_title(\"CapEx vs. Abnormal Volume\")\naxes[0].axhline(y=1.0, color=\"red\", linestyle=\"--\", alpha=0.5)\n\nvalid2 = capex_df.dropna(subset=[\"capex_intensity\", \"vol_change\"])\naxes[1].scatter(valid2[\"capex_intensity\"], valid2[\"vol_change\"],\n                alpha=0.5, s=20, color=COLOR_CAPEX)\naxes[1].set_xlabel(\"CapEx Intensity\")\naxes[1].set_ylabel(\"Volatility Change\")\naxes[1].set_title(\"CapEx vs. Volatility Change\")\naxes[1].axhline(y=0, color=\"red\", linestyle=\"--\", alpha=0.5)\n\nfig.tight_layout()\nfig.savefig(FIGURE_DIR / \"stat_capex_scatter.png\", dpi=150, bbox_inches=\"tight\")\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9py2ygh4m8i",
   "source": "# OLS Regressions\nprint(\"=\" * 70)\nprint(\"Model 1: AbVol[0,+5] ~ capex_intensity + rd_intensity + period_dummies\")\nprint(\"=\" * 70)\nmodel1 = run_ols_regression(capex_df, \"abvol_0_5\",\n                            [\"capex_intensity\", \"rd_intensity\"],\n                            add_period_dummies=True)\nprint(model1.summary())\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Model 2: VolChange ~ capex_intensity + rd_intensity + period_dummies\")\nprint(\"=\" * 70)\nmodel2 = run_ols_regression(capex_df, \"vol_change\",\n                            [\"capex_intensity\", \"rd_intensity\"],\n                            add_period_dummies=True)\nprint(model2.summary())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "zdfvm8n555a",
   "source": "## 6. Cross-Sectional Analysis\n\nHow do market reactions vary by event characteristics: agent type, AI vendor, sector, and use case?",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "j76w3d5kdfn",
   "source": "# 2x2 grid: mean AbVol by agent_type, ai_vendor, sector, use_case\nfig, axes = plt.subplots(2, 2, figsize=(15, 11))\n\ncross_cols = [\n    (\"agent_type\", \"Agent Type\"),\n    (\"ai_vendor\", \"AI Vendor\"),\n    (\"sector\", \"Sector\"),\n    (\"use_case\", \"Use Case\"),\n]\n\nfor ax, (col, label) in zip(axes.flat, cross_cols):\n    data = abvol_df.dropna(subset=[\"abvol_0_5\"]).copy()\n    if col == \"ai_vendor\":\n        data[col] = data[col].fillna(\"Not Disclosed\")\n    data = data.dropna(subset=[col])\n\n    summary = data.groupby(col)[\"abvol_0_5\"].agg([\"mean\", \"sem\", \"count\"]).reset_index()\n    summary[\"ci_95\"] = summary[\"sem\"] * 1.96\n    summary = summary.sort_values(\"mean\", ascending=True)\n\n    ax.barh(summary[col], summary[\"mean\"], xerr=summary[\"ci_95\"],\n            color=COLOR_VOLUME, edgecolor=\"white\", capsize=3, alpha=0.8)\n    ax.axvline(x=1.0, color=\"red\", linestyle=\"--\", alpha=0.6)\n    ax.set_xlabel(\"Mean Abnormal Volume [0,+5]\")\n    ax.set_title(f\"AbVol by {label}\")\n\n    # Annotate sample sizes\n    for _, r in summary.iterrows():\n        ax.annotate(f\"n={int(r['count'])}\", (r[\"mean\"] + r[\"ci_95\"] + 0.01, r[col]),\n                    fontsize=8, va=\"center\", color=\"gray\")\n\nfig.suptitle(\"Cross-Sectional Abnormal Volume Analysis\", fontsize=14, y=1.01)\nfig.tight_layout()\nfig.savefig(FIGURE_DIR / \"stat_cross_sectional.png\", dpi=150, bbox_inches=\"tight\")\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "socb7mea3m",
   "source": "# Cross-sectional ANOVA tests\nprint(\"=== Cross-Sectional ANOVA Tests (AbVol [0,+5]) ===\\n\")\nfor col, label in cross_cols:\n    data = abvol_df.dropna(subset=[\"abvol_0_5\"]).copy()\n    if col == \"ai_vendor\":\n        data[col] = data[col].fillna(\"Not Disclosed\")\n    data = data.dropna(subset=[col])\n    \n    result = test_period_differences(data, \"abvol_0_5\", col)\n    sig = \"***\" if result[\"f_pval\"] < 0.001 else (\"**\" if result[\"f_pval\"] < 0.01 else (\"*\" if result[\"f_pval\"] < 0.05 else \"ns\"))\n    print(f\"{label}: F={result['f_stat']:.3f}, p={result['f_pval']:.4f} {sig}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cr65f16bpvw",
   "source": "## 7. Summary of Results",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "vzuh7m3faai",
   "source": "# Consolidated summary table\nall_tests = {\n    \"AbVol [-1,+1] > 1\": abvol_tests[\"abvol_-1_1\"],\n    \"AbVol [0,+5] > 1\": abvol_tests[\"abvol_0_5\"],\n    \"AbVol [0,+10] > 1\": abvol_tests[\"abvol_0_10\"],\n    \"AbVol [0,+20] > 1\": abvol_tests[\"abvol_0_20\"],\n    \"Pre vs Post Vol\": vol_test,\n    \"AbVol by Period (ANOVA)\": {\"f_stat\": abvol_period_test[\"f_stat\"],\n                                 \"f_pval\": abvol_period_test[\"f_pval\"],\n                                 \"n\": sum(abvol_period_test[\"group_ns\"].values())},\n    \"VolChange by Period (ANOVA)\": {\"f_stat\": vol_period_test[\"f_stat\"],\n                                     \"f_pval\": vol_period_test[\"f_pval\"],\n                                     \"n\": sum(vol_period_test[\"group_ns\"].values())},\n    \"CapEx: High vs Low (AbVol)\": capex_test,\n    \"CapEx: High vs Low (VolChange)\": capex_vol_test,\n}\n\nsummary_table = format_test_results_table(all_tests)\nprint(\"=\" * 80)\nprint(\"COMPREHENSIVE TEST RESULTS SUMMARY\")\nprint(\"=\" * 80)\ndisplay(summary_table)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2x54ehglii",
   "source": "### Key Findings\n\n1. **Trading Intensity**: AI adoption disclosures are associated with [significant/insignificant] abnormal trading volume in the days following the announcement, consistent with heightened investor attention.\n\n2. **Volatility Impact**: Post-event volatility [increases/stays the same/decreases] compared to the pre-event baseline, suggesting AI disclosures [do/do not] introduce uncertainty into stock pricing.\n\n3. **Time Trend (Attenuation Hypothesis)**: The magnitude of market reactions [has/has not] diminished from early AI periods (2015-2017) to the current era (2024-2025), [supporting/contradicting] the hypothesis that AI disclosures have become normalized.\n\n4. **CapEx Interaction**: Firms with higher AI-related capital expenditure [show stronger/weaker/similar] market reactions, suggesting that CapEx spending [amplifies/dampens/does not affect] investor response.\n\n5. **Cross-Sectional Variation**: Market reactions [do/do not] vary significantly across agent types, AI vendors, sectors, and use cases.\n\n*Note: Replace bracketed text with actual findings after running the analysis.*",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "sfgbvc3nzm",
   "source": "### Limitations\n\n- **Small samples per bin**: ~200 events divided into 4 period bins yields some bins with <20 observations. Non-parametric tests are used as primary evidence.\n- **Overlapping events**: Multiple AI announcements per ticker may have overlapping event windows, potentially confounding volume and volatility estimates.\n- **Mock data**: Results above are based on simulated data. Statistical significance patterns will differ with real market data.\n- **Missing EDGAR data**: CapEx analysis is limited to events with matched EDGAR filings.\n- **Confounding factors**: Broader market conditions, earnings announcements, and other corporate events are not controlled for.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}